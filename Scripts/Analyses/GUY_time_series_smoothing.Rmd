---
title: "TPW Growth and Decay Models"
output: html_notebook
author: "Guy Lomax"
date: 2023-03-24
---

This notebook imports Sentinel-2 band and vegetation index time series data
from Google Earth Engine for the Tanzania People and Wildlife plots, cleans the
time series data by smoothing and gapfilling, then fits a series of simple
exponential, logistic and linear models to the growth phase and decay phase of
the NDVI curve in each season.


```{r setup}

# Analysis
library(signal)
library(imputeTS)

# Data management
library(here)
library(tidyverse)
library(lubridate)
library(sf)

# Visualisation
library(ggthemes)

```

# Load data

Data are in the form of a csv downloaded from Google Earth Engine containing
Sentinel-2 surface reflectances for the RGBIR bands, as well as NDVI and MSAVI
estimates, for every image in the L2A collection that intersects each point.

Clouds, cloud shadows and other problem pixels have already been removed using
the L2A product's SCA pixel classification flags, but clouds, shadows and
other atmospheric noise may remain.


```{r load_data}

tpw_ts_all <- read_csv(here("data", "processed", "csv", "tpw",
                            "tpwTSValues_all.csv")) %>%
  select(-"system:index", -".geo") %>%
  rename(blue = B2,
         green = B3,
         red = B4,
         ir = B8,
         lc = Map) %>%
  filter(lc != 80)  # Remove pixels sometimes within lake boundaries

# Merge double readings (if more than one value in a day) by taking higher ndvi
# value or lower raw band value (likely to be least cloud-contaminated)

# Import function s() from hablar package - manages NA values intuitively

s <- hablar::s

tpw_ts_unique <- tpw_ts_all %>%
  group_by(plot_id, imgDate) %>%
  summarise(blue = min(s(blue)), green = min(s(green)),
            red = min(s(red)), ir = min(s(ir)),
            ndvi = max(s(ndvi)), msavi = max(s(msavi)),
            lc = first(lc), precipitation = first(precipitation)) %>%
  ungroup()

tpw_ts_unique %>%
  filter(plot_id == "Alasukutan") %>%
  ggplot(aes(x = imgDate, y = ndvi)) +
  geom_line() +
  theme_bw() +
  ylim(0, 1)


```

Create smooth, continuous time series by filling NA values using intelligent
gapfilling algorithm from Chen et al. (2004) based on Savitzky-Golay filtering.
The method also boosts values identified as likely cloud-contaminated that have
not been removed by the Sentinel-2 quality assessment algorithm.

```{r gapfilling}

# First remove points with subsequent increase of > 0.1 in 5 days (assume cloud)
# Then linear interpolation for all gaps
tpw_all_int <- tpw_ts_unique %>%
  group_by(plot_id) %>%
  arrange(imgDate) %>%
  mutate(ndvi_spike = (lead(ndvi) - ndvi) > 0.1,
         ndvi = na_if(ndvi, (ndvi_spike * ndvi)),
         ndvi_int = na_interpolation(ndvi)) %>%
  select(-ndvi_spike)
         

# Apply Savitzky-Golay filter to smooth signal
# For now, use m = 60 days (12 images either side) and d = 3
# Allowing the smoother to optimise internally (as recommended in Chen et al.
# 2004) tends to lead to overfitting as there is no penalty on wiggliness.

# sg_params <- tibble(p = rep(2:4, 7),
#                     m = rep(8:14, each = 3))
# 
# # Find optimal smoothing values for each time series
# find_least_error <- function(ts) {
#   # Calculate sum of squared errors for each combination of parameters
#   sse <- numeric(length = nrow(sg_params))
#   
#   for (i in seq_len(nrow(sg_params))) {
#     p <- sg_params$p[i]
#     m <- sg_params$m[i]
#     
#     new_ts <- sgolayfilt(ts, p = p, n = 2 * m + 1)
#     
#     sse[i] <- sum((ts - new_ts) ^ 2)
#   }
#   
#   # Choose iteration which has minimum sse
#   opt <- which.min(sse)
#   opt
# }

# tpw_sg1_opt <- tpw_all_int %>%
#   group_by(plot_id) %>%
#   mutate(opt = find_least_error(ndvi_int))

tpw_sg1 <- tpw_all_int %>%
  group_by(plot_id) %>%
  mutate(ndvi_filtered = sgolayfilt(ndvi_int, p = 3, n = 25))

# Assign weights to NDVI values in original (interpolated) series based on
# whether they fall above or below the trend curve for that TS.

tpw_weights <- tpw_sg1 %>%
  mutate(dist = ndvi_filtered - ndvi_int,
         max_dist = max(dist),
         weight = ifelse(dist > 0, 1 - (dist / max_dist), 1))

# Iterative approach to upper ndvi envelope
# Generate new time series by replacing "noisy" NDVI values with filtered ones
# Second, shorter-period SG filter

iterative_fit <- function(ndvi_1, ndvi_0, weight) {
  
  initial_fit <- 100
  new_fit <- sum(abs(ndvi_1 - ndvi_0) * weight)
  ndvi_new <- ndvi_1

  while(initial_fit > new_fit) {
    initial_fit <- new_fit
    
    ndvi_new <- ifelse(ndvi_new >= ndvi_0, ndvi_new, ndvi_0) %>%
    sgolayfilt(p = 4, n = 21)
  
  new_fit <- sum(abs(ndvi_new - ndvi_0) * weight)
  }
  ndvi_new
}

# Iterate to get final time series

tpw_final <- tpw_weights %>%
  mutate(ndvi_new = iterative_fit(ndvi_filtered, ndvi_int, weight))

tpw_final %>%
  filter(plot_id == "Alasukutan") %>%
  pivot_longer(cols = c("ndvi_int", "ndvi_filtered", "ndvi_new"),
               names_to = "var", values_to = "value") %>%
  ggplot() +
  geom_line(aes(x = imgDate, y = value, colour = var)) +
  theme_bw() +
  scale_x_date(breaks = "6 months", minor_breaks = "3 month") +
  ylim(0, 1) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 60, vjust = 0.5, hjust=1))

```
