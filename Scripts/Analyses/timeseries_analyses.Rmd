```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, include=FALSE}
library(RColorBrewer)
library(lattice)
library(tidyverse)
library(here)
library(tictoc)


library(ggplot2)
library(ggpubr)
library(sf)
library(terra)

library(tmap)
library(tmaptools)
library(RColorBrewer)
library(viridis)

terraOptions(memfrac=0.5, tempdir = here("Scratch"), progress=10)
```

##Introduction
In this script I explore the time series decomposition and then regression analyses of the decomposed components of the monthly anisoEVI values. 

##Data input
```{r}
masked_evi_list <- list.files(path = here("Outputs", "Indices", "Masked_anisoEVI"), pattern='.tif$', all.files=TRUE, full.names=TRUE)
masked_evi_list<-gtools::mixedsort(masked_evi_list) #arranging rasters chronologically
masked_evi_raster_list<-lapply(masked_evi_list, rast)
aniso_evi<- rast(masked_evi_raster_list)

##changing band names to year and months
colnames<- list()
tic(); for ( i in 1:length(masked_evi_list)){
  x<- paste0(strsplit(strsplit(masked_evi_list[i], "/")[[1]][10], "_")[[1]][1], "_", strsplit(strsplit(masked_evi_list[i], "/")[[1]][10], "_")[[1]][2])
  colnames[[i]] <-x
}; toc()
colnames<- unlist(colnames)
names(aniso_evi)<- colnames

d_trans<- st_read(here ("Data", "Cattelanetal_Clustering", "cerrado_climate_zones.shp"))
d_trans<- st_transform(d_trans, crs = 4326)

buffer<- st_read(here ("Data", "Cattelanetal_Clustering", "buffer_climate_zones.shp"))

```

################################## UNDERSTANDING SEASONAL CYCLE INCLUDING DECOMPOSITION (using BFAST and BFASTLite) & DIFFERENCING

##Decomposition analyses using Bfast
Marina and I discussed decomposing the trend into seasonal and long term trend using the BFAST (Breaks For Additive Seasonal and Trend) algorithm (Verbesselt et al., 2010). I read the Jong et al., 2012 GCB paper about global greening and browning and found it pretty solid. So here I try it out. There is a R package and here I try to better understand it. https://bfast.r-forge.r-project.org/

Also see this post comparing bfast and Rbeast- https://stackoverflow.com/questions/52708697/detect-changes-in-the-seasonal-component-using-bfast. First trying bfast 

#1. First, I select 50 random pixels (points) across the buffered climate zones i.e only one big area across the entire buffer

```{r}
#install.packages(c("Rbeast", "bfast"))

buffer
random_points<-terra::spatSample(vect(buffer), size = 350, method = "random") #350 random points to get good coverage within the actual cerrado boundary
plot(random_points)

random_points_cerrado<- terra::crop(random_points, vect(d_trans))
random_points_cerrado<- terra::mask(random_points_cerrado, vect(d_trans)) #197 points out of 350 total points

random_points_cerrado<- st_as_sf(random_points_cerrado) %>% mutate(PointID= 1:dim(random_points_cerrado)[1])
random_points_cerrado<- random_points_cerrado %>% st_join(d_trans)
random_points_cerrado$region
st_write(random_points_cerrado, here("Outputs","bfastTrials", "randompoints_generated_bfast_trial.shp"))
remove(random_points)

#neighbors<- st_read(here("Data", "Admin", "brazil_neighbors.shp"))

#map_extent<- st_bbox(c(xmin=-77.59, xmax=-31.09,
#ymin=6.42, ymax=-33.49), crs=4326) %>% st_as_sfc()

#random_points_map<-tm_shape(neighbors, bbox = map_extent)+ tm_borders()+
#  tm_shape(d_trans)+ tm_fill()+
#  tm_shape( st_as_sf(random_points_cerrado))+ tm_dots()+
#              tm_layout (legend.position = c("left", "bottom"))+
#              tm_facets(nrow=1, ncol=1, free.coords = FALSE)
#tmap_save(random_points_map, here("Outputs", "bfastTrials","random_points_map.png") )
#remove(neighbors, map_extent, random_points_map)
```
(DO NOT RUN ABOVE, ALREADY WRITTEN OUT)

#2. Trial BFAST
```{r}
library(bfast)
#Sampling anisoEVI through time in the random pixels
all_random_points<- st_read(here("Outputs", "bfastTrials", "randompoints_generated_bfast_trial.shp"))
tic(); anisoEVI_random_points<- terra::extract(aniso_evi, all_random_points, method= "simple", xy=TRUE, bind=T); toc()
anisoEVI_random_points<- as.data.frame(anisoEVI_random_points)

anisoEVI_random_points<- anisoEVI_random_points %>% 
  mutate(na_count= rowSums(is.na(select(.,-c(id, PointID, ID_1, region, x, y))))) 
anisoEVI_random_points<- anisoEVI_random_points %>%
                          dplyr::filter(na_count!=251) #%>% 
#removing points that have all anisoEVI missing i.e. na_count=251 #185 values left

# Trial BFAST across above points
#The main parameter to be input is h. h is calculated as the minimal segment size between potentially detected breaks in the trend model given as fraction relative to the sample size (i.e. the minimal number of observations in each segment divided by the total length of the timeseries). 
#So I understand in terms of number of points of season switches i.e 2 a year which is 2*21 across the entire time-series 
#which means h= (2*21)/261 (because h is a proportion). So trying this out for all random points below


for (i in 1:dim(anisoEVI_random_points)[1]){
  print (paste0("Point number ", i))
  one_point<- anisoEVI_random_points[i,] %>% dplyr::select(-c(id, PointID, ID_1, region, x, y, na_count))
  print ("Creating time series object")
  x.ts <- ts(unlist(one_point), frequency = 12) 
  tic(); trial<- bfast::bfast(x.ts, h= 0.47, season = "harmonic", max.iter = 20); toc()
  print ("Completed bfast decomposition")
  dev.new()
  jpeg(here("Outputs", "bfastTrials","bfast","h_0.47", paste0("decomposition_point_", anisoEVI_random_points$PointID[i], ".jpg")))
  plot(trial)
  graphics.off()
  print ("Check jpeg file on disk")
}

#PointID=99 did not go through because over half of the series is NA
#reran above for h=0.159 ((2*21)/251), h=0.25, h=0.318 ((4*21)/251), h=0.47 ((6*21)/251)



```

#3. Trial BFASTLite
The main thing about bfast lite I do not 'like' or do not understand is the 'order' which is a 'harmonic term' and defaults to 3. So I dug deeper and found this article https://lpsa.swarthmore.edu/Fourier/Series/WhyFS.html

So order is basically the harmonic term in a fourier series. And higher the order, the better the approximation to the i.e. sum of average+ season gets closest to original observations. I think higher the term, greater the frequency of the 'season' and shorter the time period within which the season happens. 

I do not include/think about lag, slag and na.action terms for now. For breaks, I let the algorithm automatically determine the optimal number of breaks based on LWZ metric (see bfastlite original paper). I also do not do any STL adjustment so stl="none"

I do a couple of trials below. For the default trial1 I follow the example in the R help for bfastlite. In the example, the break is at the 99th observation (out of 199). And then the example uses strucchangeRcpp::breakpoints with number of breaks specified as 2. I do not understand why. Same with plotting the bfastlite model, the example says breaks=2. I do not know why!  

```{r}
#default order=3
#one_point<- anisoEVI_random_points[i,] %>% dplyr::select(-c(id, PointID, ID_1, region, x, y)) #has only 1 NA in Jan 2003
#x.ts <- ts(unlist(one_point), frequency = 12) 
#tic(); trial1<- bfast::bfastlite(x.ts, order=3, breaks = "LWZ", lag = NULL, slag = NULL, na.action = na.omit, stl = "trend"); toc()
#NA breakpoints
#plot(trial1) # blue line is the breakpoint, green line is the fitted model

#default order=7
#tic(); trial2<- bfast::bfastlite(x.ts, order=7, breaks = "LWZ", lag = NULL, slag = NULL, na.action = na.omit, stl = "none"); toc()
#Again NA breakpoints

breakpoints<-anisoEVI_random_points
breakpoints<- breakpoints %>% mutate(ObservationBreakpoint=NA)
tic(); for (i in 162:dim(anisoEVI_random_points)[1]){
  print (paste0("Point number ", i))
  one_point<- anisoEVI_random_points[i,] %>% dplyr::select(-c(id, PointID, ID_1, region, x, y, na_count))
  print ("Creating time series object")
  x.ts <- ts(unlist(one_point), frequency = 12) 
  tic(); trial<- bfast::bfastlite(x.ts, order=5, breaks="LWZ", lag=NULL, slag=NULL, na.action= na.omit, stl="none")
  print ("Completed bfastlite analyses")
  breakpoint<- trial$breakpoints$breakpoints
  print (breakpoint)
  breakpoints$ObservationBreakpoint[i]<- breakpoint
  print ("Breakpoint observation number saved")
  dev.new()
  jpeg(here("Outputs","bfastTrials", "bfastlite", "Order5", paste0("bfastlite_point_",anisoEVI_random_points$PointID[i], ".jpg")))
  plot(trial)
  graphics.off()
  print ("Check jpeg file on disk")
}; tic()

#PointID=36, 38, 99, 115, 170- these have more than half of their anisoEVI values as NA in different stretches of the time series

```


#4. Trying to understand how piecewise linear regression deals with NA
Using the time series anisoEVI data in the random points above, I do some EDA with linear regression to understand how lm() in R treats time series data with NA. 

```{r}
pivot_all_random_points<- pivot_longer(anisoEVI_random_points, cols = 2:262)

no_NA<- pivot_all_random_points %>% dplyr::select(-c(x,y)) %>%
  group_by(ID) %>%  summarise(sum_na = sum(is.na(value)))


absent_NA<- pivot_all_random_points %>% filter(ID==60)
absent_NA<- absent_NA %>% separate_wider_delim(cols = name, delim = "_", names = c("Year","Month"))
absent_NA<- absent_NA %>% mutate(Date= paste0(Year,"_", Month, "_01"))
absent_NA<- absent_NA %>% mutate(Date= lubridate::as_date(Date))
median_3NA<- pivot_all_random_points %>% filter(ID==147)
median_3NA<- median_3NA %>% separate_wider_delim(cols = name, delim = "_", names = c("Year","Month"))
median_3NA<- median_3NA %>% mutate(Date= paste0(Year,"_", Month, "_01"))
median_3NA<- median_3NA %>% mutate(Date= lubridate::as_date(Date))
max_46NA<- pivot_all_random_points %>% filter(ID==7)
max_46NA<- max_46NA %>% separate_wider_delim(cols = name, delim = "_", names = c("Year","Month"))
max_46NA<- max_46NA %>% mutate(Date= paste0(Year,"_", Month, "_01"))
max_46NA<- max_46NA %>% mutate(Date= lubridate::as_date(Date))
#absent_NA<- ts(absent_NA %>% dplyr::select(value),
#                start=c(2000,3), end=c(2021,12), frequency=12)
m = lm(value ~ Date, data = absent_NA)
m1 = lm(value ~ Date, data = median_3NA)
m2 = lm(value ~ Date, data = max_46NA)


```
Basically, lm() can handle NA. It excludes the NA points completely. As NAs increase, the lm still runs but the residual error increases and there is cost of losing degrees of freedom

#5. Differencing as an alternative to decomposition
I was reading about this article about removing seasonal trend from data. It says that 'differencing' is an alternative to decomposition. So I try that in the chunk below
https://atsa-es.github.io/atsa-labs/sec-tslab-differencing-to-remove-a-trend-or-seasonal-effects.html

Specifically look at last sentence under 4.3.1
" In addition, first-differencing a time series at a lag equal to the period will remove a seasonal trend (e.g., set lag = 12 for monthly data)."

```{r}
#I have to change the format of the df to do differencing
anisoEVI_random_points
pivot_anisoEVI_random_points<- pivot_longer(anisoEVI_random_points, cols = 5:255)#5:255 are the cols with anisoEVI values

newformat<- pivot_anisoEVI_random_points %>% separate_wider_delim(cols = name, delim = "_", names = c("Year","Month"))
newformat<- newformat %>% mutate(Date= paste0(Year,"_", Month, "_01"))
newformat<- newformat %>% mutate(Date= lubridate::as_date(Date))

pointid_vector<- unique(anisoEVI_random_points$PointID)

tic(); for (i in 1:length(pointid_vector)){
  x <- newformat %>% dplyr::filter(PointID==pointid_vector[i]) #trial
  x_d1_lag12<- timeSeries::diff(x$value,differences = 1, lag = 12)
  print ("Plot original values")
  original<- ggplot(data=x, aes(x=(Date), y= value))+
    geom_line() + theme_bw() + ylab("Original anisoEVI at point")+
    ggtitle(paste0("n=",length(x$value),";NA-count (out of 251)", x$na_count))
  x_d1_lag12<- as.data.frame(x_d1_lag12)
  x_d1_lag12$index <- 1:nrow(x_d1_lag12)
  print ("Plot differenced values")
  difference<-  ggplot(data=x_d1_lag12, aes(x=index, y=x_d1_lag12))+
    geom_line() + theme_bw() + ylab("Differenced anisoEVI")+
    ggtitle(paste0("n=",dim(x_d1_lag12)[1],";NA-count (out of 251)", sum(is.na(x_d1_lag12)))) 
  print ("Saving image")
  both<-ggarrange(original, difference, nrow=2)
  ggsave(here("Outputs", "differencingTrials", paste0("difference_", pointid_vector[i], ".png")), plot=both)
}; toc()

```


I consider points that I have been testing out, but points that have 0 NAs in the time series. This way I can compare the results of the stl decomposition with the differencing results and see what is happening. 

```{r}
no_NA<- anisoEVI_random_points %>% dplyr::filter(na_count==0) #33 points
pivot_no_NA<- pivot_longer(no_NA, cols = 5:255)#5:255 are the cols with anisoEVI values

library(stlplus)
no_NA_id<- unique(pivot_no_NA$PointID)
for (i in 1:length(no_NA_id)){
  x<- no_NA %>% dplyr::filter(PointID==no_NA_id[i]) %>% dplyr::select(-c(id, PointID, ID_1, region, x, y, na_count))
  x_ts<- ts(unlist(x), frequency = 12) 
  stl_decompose<- stlplus::stlplus(x_ts, s.window="periodic")
  x_prep<- pivot_longer(x, cols = 1:251)  
  differencing<- timeSeries::diff(x_prep$value, differences = 1, lag = 12)
  dev.new()
  jpeg(here("Outputs", "differencingTrials", "Differencing_vs_Decomposition", paste0("compare_",no_NA_id[i], ".jpg")), width = 30, height = 30, units="cm", res=72)
  par(mfrow = c(5, 1))
  plot(stl_decompose$data$raw, type="l")
  plot(stl_decompose$data$seasonal, type="l")
  plot(stl_decompose$data$trend, type="l")
  plot(stl_decompose$data$remainder, type="l")
  plot(differencing, type="l")
  graphics.off()
}


```

Basically the results of the differencing and the decomposition does not match up at all! At first I thought that the differencing results matches the residuals after removing trend and season in the decomposition analyses. It slightly matches, but not exactly. Firstly, the residuals from decomposition and differencing are off by couple of decimal place. Second, the differencing results literally has lesser number of resulting values i.e. for example with 251 non NA values, the differencing results in 239 values. The decomposition residuals still has 251 values.

#1- No trend lm
```{r}
no_trend_coef_fun <- function(x) { 
  if (is.na(x[1])){ NA } 
  else { m = lm(x ~ 1); #no trend means, the resulting x will be the mean of all the time series NDVI
  summary(m)$coefficients[1] 
  }}
tic(); no_trend.slope<- terra::app(aniso_evi, no_trend_coef_fun); toc()
plot(no_trend.slope, main="slope")
```



#2- Trying out linear regression curve fitting as per
https://matinbrandt.wordpress.com/2013/11/15/pixel-wise-time-series-trend-anaylsis-with-ndvi-gimms-and-r/
```{r}
time <- 1:nlyr(aniso_evi) 
lm_coef_fun <- function(x) { 
  if (is.na(x[1])){ NA } #if all pixels in the first column (ie same pixels through time) are NA, then result is NA
  else { m = lm(x ~ time); 
  summary(m)$coefficients[2] 
  }}
tic(); evi.slope<- terra::app(aniso_evi, lm_coef_fun); toc()
plot(evi.slope, main="slope")

lm_p_fun<- function(x) { 
  if (is.na(x[1])){ NA } #if all pixels in the first column (ie same pixels through time) are NA, then result is NA
  else { m = lm(x ~ time); 
  summary(m)$coefficients[8] 
  }}
tic(); p <- terra::app(aniso_evi, fun=lm_p_fun); toc()
plot(p, main="p-Value")

m = c(0, 0.05, 1, 0.05, 1, 0) 
rclmat <- matrix(m, ncol=3, byrow=TRUE) #<0.05 is significant, so pixel values=1
tic(); p.mask <- terra::classify(p, rclmat); toc()
mask_fun<- function(x) {
  x[x<1] <- NA; #if pixel =0, then make it NA to mask out non-significant p values
  return(x)
  }
tic(); p.mask.NA<- terra:: app(p.mask, mask_fun); toc()

trend.sig <- terra::mask(evi.slope, p.mask.NA)
plot(trend.sig, main="significant NDVI change")


```

